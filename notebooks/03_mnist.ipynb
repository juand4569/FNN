{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062047dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from src.datasets import load_mnist\n",
    "from src.neural_network import NeuralNetwork\n",
    "from src.optimizers import Adam\n",
    "from src.trainer import Trainer\n",
    "from src.utils import train_val_test_split, one_hot_encode\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar MNIST\n",
    "print(\"Cargando MNIST...\")\n",
    "X_train_full, y_train_full, X_test, y_test = load_mnist()\n",
    "\n",
    "# Split train/val\n",
    "X_train, y_train, X_val, y_val, _, _ = train_val_test_split(\n",
    "    X_train_full, \n",
    "    one_hot_encode(y_train_full, 10),\n",
    "    train_ratio=0.85,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.0,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "y_test_oh = one_hot_encode(y_test, 10)\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Arquitectura: 784 -> 128 -> 64 -> 10\n",
    "architecture = [\n",
    "    (784, None),\n",
    "    (128, 'relu'),      # ReLU funciona mejor en MNIST\n",
    "    (64, 'relu'),\n",
    "    (10, 'softmax')\n",
    "]\n",
    "\n",
    "model = NeuralNetwork(architecture, loss='categorical_crossentropy')\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "# Entrenar\n",
    "print(\"\\nEntrenando...\")\n",
    "trainer.train(X_train, y_train, X_val, y_val,\n",
    "              epochs=20, batch_size=128, verbose=True)\n",
    "\n",
    "# Evaluar en test\n",
    "test_loss, test_acc = trainer.evaluate(X_test, y_test_oh)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"RESULTADO FINAL EN TEST\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "# Graficar\n",
    "trainer.plot_history()\n",
    "\n",
    "# Mostrar ejemplos de predicciones\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "indices = np.random.choice(len(X_test), 10)\n",
    "\n",
    "for idx, ax in zip(indices, axes.flat):\n",
    "    img = X_test[idx].reshape(28, 28)\n",
    "    pred = np.argmax(model.forward(X_test[idx:idx+1]))\n",
    "    true = y_test[idx]\n",
    "    \n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f'Pred: {pred}, True: {true}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred_test = model.forward(X_test)\n",
    "y_pred_labels = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_labels)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - MNIST')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#OPCIONES DE MEJORA POR SI EL ACCURACU <80%\n",
    "\n",
    "# OPCIÓN A: Red más profunda\n",
    "architecture = [\n",
    "    (784, None),\n",
    "    (256, 'relu'),\n",
    "    (128, 'relu'),\n",
    "    (64, 'relu'),\n",
    "    (10, 'softmax')\n",
    "]\n",
    "\n",
    "# OPCIÓN B: Más épocas y learning rate menor\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "trainer.train(..., epochs=50, batch_size=64)\n",
    "\n",
    "# OPCIÓN C: Mejor inicialización (He para ReLU)\n",
    "# Modificar en layers.py el __init__ de Dense:\n",
    "\n",
    "'''\n",
    "if weight_init == 'he':\n",
    "    self.W = np.random.randn(n_inputs, n_neurons) * np.sqrt(2/n_inputs)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
